{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yassaadi/bank_scoring/blob/main/AWS_EMR_Assaadi_Yassine_1_notebook_052022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "a0f0f7c1"
      },
      "cell_type": "markdown",
      "source": [
        "²# 4. Déploiement de la solution sur le cloud\n",
        "\n",
        "Maintenant que nous avons vérifié que notre solution fonctionne, <br />\n",
        "il est temps de la <u>déployer à plus grande échelle sur un vrai cluster de machines</u>.\n",
        "\n",
        "**Attention**, *je travaille sous Linux avec une version Ubuntu, <br />\n",
        "les commandes décrites ci-dessous sont donc réalisées <br />\n",
        "exclusivement dans cet environnement.*\n",
        "\n",
        "<u>Plusieurs contraintes se posent</u> :\n",
        " 1. Quel prestataire de Cloud choisir ?\n",
        " 2. Quelles solutions de ce prestataire adopter ?\n",
        " 3. Où stocker nos données ?\n",
        " 4. Comment configurer nos outils dans ce nouvel environnement ?\n",
        " \n",
        "## 4.1 Choix du prestataire cloud : AWS\n",
        "\n",
        "Le prestataire le plus connu et qui offre à ce jour l'offre <br />\n",
        "la plus large dans le cloud computing est **Amazon Web Services** (AWS).<br />\n",
        "Certaines de leurs offres sont parfaitement adaptées à notre problématique <br />\n",
        "et c'est la raison pour laquelle j'utiliserai leurs services.\n",
        "\n",
        "L'objectif premier est de pouvoir, grâce à AWS, <u>louer de la puissance de calcul à la demande</u>. <br />\n",
        "L'idée étant de pouvoir, quel que soit la charge de travail, <br />\n",
        "obtenir suffisamment de puissance de calcul pour pouvoir traiter nos images, <br />\n",
        "même si le volume de données venait à fortement augmenter.\n",
        "\n",
        "De plus, la capacité d'utiliser cette puissance de calcul à la demande <br />\n",
        "permet de diminuer drastiquement les coûts si l'on compare les coûts d'une location <br />\n",
        "de serveur complet sur une durée fixe (1 mois, 1 année par exemple).\n",
        "\n",
        "## 4.2 Choix de la solution technique : EMR\n",
        "\n",
        "<u>Plusieurs solutions s'offre à nous</u> :\n",
        "1. Solution **IAAS** (Infrastructure AS A Service)\n",
        " - Dans cette configuration **AWS** met à notre disposition des serveurs vierges <br />\n",
        "   sur lequel nous avons un accès en administrateur, ils sont nommés **instance EC2**.<br />\n",
        "   Pour faire simple, nous pouvons avec cette solution reproduire pratiquement <br />\n",
        "   à l'identique la solution mis en œuvre en local sur notre machine.<br />\n",
        "   <u>On installe nous-même l'intégralité des outils puis on exécute notre script</u> :\n",
        "  - Installation de **Spark**, **Java** etc.\n",
        "  - Installation de **Python** (via Anaconda par exemple)\n",
        "  - Installation de **Jupyter Notebook**\n",
        "  - Installation des **librairies complémentaires**\n",
        "  - Il faudra bien évidement veiller à **implémenter les librairies \n",
        "    nécessaires à toutes les machines (workers) du cluster**\n",
        "  - <u>Avantages</u> :\n",
        "      - Liberté totale de mise en œuvre de la solution\n",
        "      - Facilité de mise en œuvre à partir d'un modèle qui s'exécute en local sur une machine Linux\n",
        "  - <u>Inconvénients</u> :\n",
        "      - Cronophage\n",
        "          - Nécessité d'installer et de configurer toute la solution\n",
        "      - Possible problèmes techniques à l'installation des outils (des problématiques qui <br />\n",
        "        n'existaient pas en local sur notre machine peuvent apparaitre sur le serveur EC2)\n",
        "      - Solution non pérenne dans le temps, il faudra veiller à la mise à jour des outils <br />\n",
        "        et éventuellement devoir réinstaller Spark, Java etc. \n",
        "2. Solution **PAAS** (Plateforme As A Service)\n",
        " - **AWS** fournit énormément de services différents, dans l'un de ceux-là <br />\n",
        "   il existe une offre qui permet de louer des **instances EC2** <br />\n",
        "   avec des applications préinstallées et configurées : il s'agit du **service EMR**.\n",
        " - **Spark** y sera déjà installé\n",
        " - Possibilité de demander l'installation de **Tensorflow** ainsi que **JupyterHub**\n",
        " - Possibilité d'indiquer des **packages complémentaires** à installer <br />\n",
        "   à l'initialisation du serveur **sur l'ensemble des machines du cluster**.\n",
        " - <u>Avantages</u> :\n",
        "     - Facilité de mise en œuvre\n",
        "         - Il suffit de très peu de configuration pour obtenir <br />\n",
        "           un environnement parfaitement fonctionnel\n",
        "     - Rapidité de mise en œuvre\n",
        "         - Une fois la première configuration réalisée, il est très facile <br />\n",
        "           et très rapide de recréer des clusters à l'identique qui seront <br />\n",
        "           disponibles presque instantanément (le temps d'instancier les <br />\n",
        "           serveurs soit environ 15/20 minutes)\n",
        "     - Solutions matérielless et logicielles optimisées par les ingénieurs d'AWS\n",
        "         - On sait que les versions installées vont fonctionner <br />\n",
        "           et que l'architecture proposée est optimisée\n",
        "     - Stabilité de la solution\n",
        "    - Solution évolutive\n",
        "        Il est facile d’obtenir à chaque nouvelle instanciation une version à jour <br />\n",
        "        de chaque package, en étant garanti de leur compatibilité avec le reste de l’environnement.\n",
        "  - Plus sécurisé\n",
        "\t- Les éventuels patchs de sécurité seront automatiquement mis à jour <br />\n",
        "      à chaque nouvelle instanciation du cluster EMR.\n",
        " - <u>Inconvénients</u> :\n",
        "     - Peut-être un certain manque de liberté sur la version des packages disponibles ? <br />\n",
        "       Même si je n'ai pas constaté ce problème.\n",
        "   \n",
        "\n",
        "Je retiens la solution **PAAS** en choisissant d'utiliser <br />\n",
        "le service **EMR** d'Amazon Web Services.<br />\n",
        "Je la trouve plus adaptée à notre problématique et permet <br />\n",
        "une mise en œuvre qui soit à la fois plus rapide et <br />\n",
        "plus efficace que la solution IAAS.\n",
        "\n",
        "## 4.3 Choix de la solution de stockage des données : Amazon S3\n",
        "\n",
        "<u>Amazon propose une solution très efficace pour la gestion du stockage des données</u> : **Amazon S3**. <br />\n",
        "S3 pour Amazon Simple Storage Service.\n",
        "\n",
        "Il pourrait être tentant de stocker nos données sur l'espace alloué par le serveur **EC2**, <br />\n",
        "mais si nous ne prenons aucune mesure pour les sauvegarder ensuite sur un autre support, <br />\n",
        "<u>les données seront perdues</u> lorsque le serveur sera résilié (on résilie le serveur lorsqu'on <br />\n",
        "ne s'en sert pas pour des raisons de coût).<br />\n",
        "De fait, si l'on décide d'utiliser l'espace disque du serveur EC2 il faudra imaginer <br />\n",
        "une solution pour sauvegarder les données avant la résiliation du serveur.\n",
        "De plus, nous serions exposés à certaines problématiques si nos données venaient à <br />\n",
        "**saturer** l'espace disponible de nos serveurs (ralentissements, disfonctionnements).\n",
        "\n",
        "<u>Utiliser **Amazon S3** permet de s'affranchir de toutes ces problématiques</u>. <br />\n",
        "L'espace disque disponible est **illimité**, et il est **indépendant de nos serveurs EC2**. <br />\n",
        "L'accès aux données est **très rapide** car nous restons dans l'environnement d'AWS <br />\n",
        "et nous prenons soin de <u>choisir la même région pour nos serveurs **EC2** et **S3**</u>.\n",
        "\n",
        "De plus, comme nous le verrons <u>il est possible d'accéder aux données sur **S3** <br />\n",
        "    de la même manière que l'on **accède aux données sur un disque local**</u>.<br />\n",
        "Nous utiliserons simplement un **PATH au format s3://...** .\n",
        "\n",
        "## 4.4 Configuration de l'environnement de travail\n",
        "\n",
        "La première étape est d'installer et de configurer [**AWS Cli**](https://aws.amazon.com/fr/cli/),<br />\n",
        "il s'agit de l'**interface en ligne de commande d'AWS**.<br />\n",
        "Elle nous permet d'**interagir avec les différents services d'AWS**, comme **S3** par exemple.\n",
        "\n",
        "Pour pouvoir utiliser **AWS Cli**, il faut le configurer en créant préalablement <br />\n",
        "un utilisateur à qui on donnera les autorisations dont nous aurons besoin.<br />\n",
        "Dans ce projet il faut que l'utilisateur ait à minima un contrôle total sur le service S3.\n",
        "\n",
        "<u>La gestion des utilisateurs et de leurs droits s'effectue via le service **AMI**</u> d'AWS.\n",
        "\n",
        "Une fois l'utilisateur créé et ses autorisations configurées nous créons une **paire de clés** <br />\n",
        "qui nous permettra de nous **connecter sans à avoir à devoir saisir systématiquement notre login/mot de passe**.<br />\n",
        "\n",
        "Il faut également configurer l'**accès SSH** à nos futurs serveurs EC2. <br />\n",
        "Ici aussi, via un système de clés qui nous dispense de devoir nous authentifier \"à la main\" à chaque connexion.\n",
        "\n",
        "Toutes ses étapes de configuration sont parfaitement décrites <br />\n",
        "dans le cours du projet: [Réalisez des calculs distribués sur des données massives / Découvrez Amazon Web Services](https://openclassrooms.com/fr/courses/4297166-realisez-des-calculs-distribues-sur-des-donnees-massives/4308686-decouvrez-amazon-web-services#/id/r-4355822)\n",
        "\n",
        "## 4.5 Upload de nos données sur S3\n",
        "\n",
        "Nos outils sont configurés. <br />\n",
        "Il faut maintenant uploader nos données de travail sur Amazon S3.\n",
        "\n",
        "Ici aussi les étapes sont décrites avec précision <br />\n",
        "dans le cours [Réalisez des calculs distribués sur des données massives / Stockez des données sur S3](https://openclassrooms.com/fr/courses/4297166-realisez-des-calculs-distribues-sur-des-donnees-massives/4308691-stockez-des-donnees-sur-s3)\n",
        "\n",
        "Je décide de n'uploader que les données contenues dans le dossier **Test** du [jeu de données du projet](https://www.kaggle.com/moltean/fruits/download)\n",
        "\n",
        "\n",
        "La première étape consiste à **créer un bucket sur S3** <br />\n",
        "dans lequel nous uploaderons les données du projet:\n",
        "- **aws s3 mb s3://p8-data**\n",
        "\n",
        "On vérifie que le bucket à bien été créé\n",
        "- **aws s3 ls**\n",
        " - Si le nom du bucket s'affiche alors c'est qu'il a été correctement créé.\n",
        "\n",
        "On copie ensuite le contenu du dossier \"**Test**\" <br />\n",
        "dans un répertoire \"**Test**\" sur notre bucket \"**p8-data**\":\n",
        "1. On se place à l'intérieur du répertoire **Test**\n",
        "2. **aws sync . s3://p8-data/Test**\n",
        "\n",
        "La commande **sync** est utile pour synchroniser deux répertoires.\n",
        "\n",
        "<u>Nos données du projet sont maintenant disponibles sur Amazon S3</u>.\n",
        "\n",
        "## 4.6 Configuration du serveur EMR\n",
        "\n",
        "Une fois encore, le cours [Réalisez des calculs distribués sur des données massives / Déployez un cluster de calculs distribués](https://openclassrooms.com/fr/courses/4297166-realisez-des-calculs-distribues-sur-des-donnees-massives/4308696-deployez-un-cluster-de-calculs-distribues) <br /> détaille l'essentiel des étapes pour lancer un cluster avec **EMR**.\n",
        "\n",
        "<u>Je détaillerai ici les étapes particulières qui nous permettent <br />\n",
        "de configurer le serveur selon nos besoins</u> :\n",
        "\n",
        "1. Cliquez sur Créer un cluster\n",
        "![Créer un cluster](/content/drive/MyDrive/\"Colab Notebooks\"/P8-Fruits/P8_Mode_opératoire/img/EMR_creer.png)\n",
        "2. Cliquez sur Accéder aux options avancées\n",
        "![Créer un cluster](/content/drive/MyDrive/\"Colab Notebooks\"/P8-Fruits/P8_Mode_opératoire/img/EMR_options_avancees.png)\n",
        "\n",
        "### 4.6.1 Étape 1 : Logiciels et étapes\n",
        "\n",
        "#### 4.6.1.1 Configuration des logiciels\n",
        "\n",
        "<u>Sélectionnez les packages dont nous aurons besoin comme dans la capture d'écran</u> :\n",
        "1. Nous sélectionnons la dernière version d'**EMR**, soit la version **6.3.0** au moment où je rédige ce document\n",
        "2. Nous cochons bien évidement **Hadoop** et **Spark** qui seront préinstallés dans leur version la plus récente\n",
        "3. Nous aurons également besoin de **TensorFlow** pour importer notre modèle et réaliser le **transfert learning**\n",
        "4. Nous travaillerons enfin avec un **notebook Jupyter** via l'application **JupyterHub**<br />\n",
        " - Comme nous le verrons dans un instant nous allons <u>paramétrer l'application afin que les notebooks</u>, <br />\n",
        "   comme le reste de nos données de travail, <u>soient enregistrés directement sur S3</u>.\n",
        "![Créer un cluster](/content/drive/MyDrive/img/EMR_configuration_logiciels.png)\n",
        "\n",
        "#### 4.6.1.2 Modifier les paramètres du logiciel\n",
        "\n",
        "<u>Paramétrez la persistance des notebooks créés et ouvert via JupyterHub</u> :\n",
        "- On peut à cette étape effectuer des demandes de paramétrage particulières sur nos applications. <br />\n",
        "  L'objectif est, comme pour le reste de nos données de travail, <br />\n",
        "  d'éviter toutes les problématiques évoquées précédemment. <br />\n",
        "  C'est l'objectif à cette étape, <u>nous allons enregistrer <br />\n",
        "  et ouvrir les notebooks</u> non pas sur l'espace disque de  l'instance EC2 (comme <br />\n",
        "  ce serait le cas dans la configuration par défaut de JupyterHub) mais <br />\n",
        "  <u>directement sur **Amazon S3**</u>.\n",
        "- <u>deux solutions sont possibles pour réaliser cela</u> :\n",
        " 1. Créer un **fichier de configuration JSON** que l'on **upload sur S3** et on indique ensuite le chemin d’accès au fichier JSON\n",
        " 2. Rentrez directement la configuration au format JSON\n",
        " \n",
        "J'ai personnellement créé un fichier JSON lors de la création de ma première instance EMR, <br />\n",
        "puis lorsqu'on décide de cloner notre serveur pour en recréer un facilement à l'identique, <br />\n",
        "la configuration du fichier JSON se retrouve directement copié comme dans la capture ci-dessous.\n",
        "\n",
        "<u>Voici le contenu de mon fichier JSON</u> :  [{\"classification\":\"jupyter-s3-conf\",\"properties\":{\"s3.persistence.bucket\":\"p8-data\",\"s3.persistence.enabled\":\"true\"}}]\n",
        " Appuyez ensuite sur \"**Suivant**\"\n",
        "![Modifier les paramètres du logiciel](/content/drive/MyDrive/\"Colab Notebooks\"/P8-Fruits/P8_Mode_opératoire/img/EMR_parametres_logiciel.png)\n",
        "\n",
        "### 4.6.2 Étape 2 : Matériel\n",
        "\n",
        "A cette étape, laissez les choix par défaut. <br />\n",
        "<u>L'important ici est la sélection de nos instances</u> :\n",
        "\n",
        "1. je choisi les instances de type **M5** qui sont des **instances de type équilibrés**\n",
        "2. je choisi le type **xlarge** qui est l'instance la **moins onéreuse disponible**\n",
        " [Plus d'informations sur les instances M5 Amazon EC2](https://aws.amazon.com/fr/ec2/instance-types/m5/)\n",
        "3. Je sélectionne **1 instance Maître** (le driver) et **2 instances Principales** (les workeurs) <br />\n",
        "   soit **un total de 3 instance EC2**.\n",
        "![Choix du materiel](/content/drive/MyDrive/\"Colab Notebooks\"/P8-Fruits/P8_Mode_opératoire/img/EMR_materiel.png)\n",
        "\n",
        "### 4.6.3 Étape 3 : Paramètres de cluster généraux\n",
        "\n",
        "#### 4.6.3.1 Options générales\n",
        "<u>La première chose à faire est de donner un nom au cluster</u> :<br />\n",
        "*J'ai également décoché \"Protection de la résiliation\" pour des raisons pratiques.*\n",
        "    \n",
        "![Nom du Cluster](/content/drive/MyDrive/\"Colab Notebooks\"/P8-Fruits/P8_Mode_opératoire/img/EMR_nom_cluster.png)\n",
        "\n",
        "#### 4.6.3.2 Actions d'amorçage\n",
        "\n",
        "Nous allons à cette étape **choisir les packages manquants à installer** et qui <br />\n",
        "nous serons utiles dans l'exécution de notre notebook.<br />\n",
        "<u>L'avantage de réaliser cette étape maintenant est que les packages <br />\n",
        "installés le seront sur l'ensemble des machines du cluster</u>.\n",
        "\n",
        "La procédure pour créer le fichier **bootstrap** qui contient <br />\n",
        "l'ensemble des instructions permettant d'installer tous <br />\n",
        "les packages dont nous aurons besoin est expliqué dans <br />\n",
        "le cours [Réalisez des calculs distribués sur des données massives / Bootstrapping](https://openclassrooms.com/fr/courses/4297166-realisez-des-calculs-distribues-sur-des-donnees-massives/4308696-deployez-un-cluster-de-calculs-distribues#/id/r-4356490)\n",
        "\n",
        "Nous créons donc un fichier nommé \"**bootstrap-emr.sh**\" que nous <u>uploadons <br />\n",
        "sur S3</u>(je l’installe à la racine de mon **bucket \"p8-data\"**) et nous l'ajoutons <br />\n",
        "comme indiqué dans la capture d'écran ci-dessous:\n",
        "![Actions d'amorcage](/content/drive/MyDrive/\"Colab Notebooks\"/P8-Fruits/P8_Mode_opératoire/img/EMR_amorcage.png)\n",
        "\n",
        "Voici le contenu du fichier **bootstrap-emr.sh**<br />\n",
        "Comme on peut le constater il s'agit simplement de commande \"**pip install**\" <br />\n",
        "pour **installer les bibliothèques manquantes** comme réalisé en local.<br />\n",
        "Une fois encore, <u>il est nécessaire de réaliser ces actions à cette étape</u> <br />\n",
        "pour que <u>les packages soient installés sur l'ensemble des machines du cluster</u> <br />\n",
        "et non pas uniquement sur le driver, comme cela serait le cas si nous exécutions <br />\n",
        "ces commandes directement dans le notebook JupyterHub ou dans la console EMR (connecté au driver).\n",
        "![Contenu du fichier bootstrap](/content/drive/MyDrive/\"Colab Notebooks\"/P8-Fruits/P8_Mode_opératoire/img/EMR_bootstrap.png)\n",
        "\n",
        "**setuptools** et **pip** sont mis à jour pour éviter une problématique <br />\n",
        "avec l'installation du package **pyarrow**.<br />\n",
        "**Pandas** a eu droit à une mise à jour majeur (1.3.0) il y a moins d'une semaine <br />\n",
        "au moment de la rédaction de ce notebook, et la nouvelle version de **Pandas** <br />\n",
        "nécessite une version plus récente de **Numpy** que la version installée par <br />\n",
        "défaut (1.16.5) à l'initialisation des instances **EC2**. <u>Il ne semble pas <br />\n",
        "possible d'imposer une autre version de Numpy que celle installé par <br />\n",
        "défaut</u> même si on force l'installation d'une version récente de **Numpy** <br />\n",
        "(en tout cas, ni simplement ni intuitivement).<br />\n",
        "La mise à jour étant très récente <u>la version de **Numpy** n'est pas encore <br />\n",
        "mise à jour sur **EC2**</u> mais on peut imaginer que ce sera le cas très rapidement <br />\n",
        "et il ne sera plus nécessaire d'imposer une version spécifique de **Pandas**.<br />\n",
        "En attendant, je demande <u>l'installation de l'avant dernière version de **Pandas (1.2.5)**</u>\n",
        "\n",
        "On clique ensuite sur ***Suivant***\n",
        "\n",
        "### 4.6.4 Étape 4 : Sécurité\n",
        "\n",
        "#### 4.6.4.1 Options de sécurité\n",
        "\n",
        "A cette étape nous sélectionnons la **paire de clés EC2** créé précédemment. <br />\n",
        "Elle nous permettra de se connecter en **ssh** à nos **instances EC2** <br />\n",
        "sans avoir à entrer nos login/mot de passe.<br />\n",
        "On laisse les autres paramètres par défaut. <br />\n",
        "Et enfin, on clique sur \"***Créer un cluster***\"\n",
        " \n",
        "![EMR Sécurité](/content/drive/MyDrive/\"Colab Notebooks\"/P8-Fruits/P8_Mode_opératoire/img/EMR_securite.png)\n",
        "\n",
        "## 4.7 Instanciation du serveur\n",
        "\n",
        "Il ne nous reste plus qu'à attendre que le serveur soit prêt. <br />\n",
        "Cette étape peut prendre entre **15 et 20 minutes**.\n",
        "\n",
        "<u>Plusieurs étapes s'enchaîne, on peut suivre l'avancé du statut du **cluster EMR**</u> :\n",
        "\n",
        "![Instanciation étape 1](img/EMR_instanciation_01.png)\n",
        "![Instanciation étape 2](img/EMR_instanciation_02.png)\n",
        "![Instanciation étape 3](img/EMR_instanciation_03.png)\n",
        "\n",
        "<u>Lorsque le statut affiche en vert: \"**En attente**\" cela signifie que l'instanciation <br />\n",
        "s'est bien déroulée et que notre serveur est prêt à être utilisé</u>. \n",
        "\n",
        "## 4.8 Création du tunnel SSH à l'instance EC2 (Maître)\n",
        "\n",
        "### 4.8.1 Création des autorisations sur les connexions entrantes\n",
        "\n",
        "<u>Nous souhaitons maintenant pouvoir accéder à nos applications</u> :\n",
        " - **JupyterHub** pour l'exécution de notre notebook\n",
        " - **Serveur d'historique Spark** pour le suivi de l'exécution <br />\n",
        "   des tâches de notre script lorsqu'il sera lancé\n",
        " \n",
        "Cependant, <u>ces applications ne sont accessibles que depuis le réseau local du driver</u>, <br />\n",
        "et pour y accéder nous devons **créer un tunnel SSH vers le driver**.\n",
        "\n",
        "Par défaut, ce driver se situe derrière un firewall qui bloque l'accès en SSH. <br />\n",
        "<u>Pour ouvrir le port 22 qui correspond au port sur lequel écoute le serveur SSH, <br />\n",
        "il faut modifier le **groupe de sécurité EC2 du driver**</u>.\n",
        "\n",
        "Cette étape est décrite dans le cours [Réalisez des calculs distribués sur des données massives / Lancement d'une application à partir du driver](https://openclassrooms.com/fr/courses/4297166-realisez-des-calculs-distribues-sur-des-donnees-massives/4308696-deployez-un-cluster-de-calculs-distribues#/id/r-4356512): \n",
        "\n",
        "*Il faudra que l'on se connecte en SSH au driver de notre cluster. <br />\n",
        "Par défaut, ce driver se situe derrière un firewall qui bloque l'accès en SSH. <br />\n",
        "Pour ouvrir le port 22 qui correspond au port sur lequel écoute le serveur SSH, <br />\n",
        "il faut modifier le groupe de sécurité EC2 du driver. Sur la page de la console <br />\n",
        "consacrée à EC2, dans l'onglet \"Réseau et sécurité\", cliquez sur \"Groupes de sécurité\". <br />\n",
        "Vous allez devoir modifier le groupe de sécurité d’ElasticMapReduce-Master. <br />\n",
        "Dans l'onglet \"Entrant\", ajoutez une règle SSH dont la source est \"N'importe où\" <br />\n",
        "(ou \"Mon IP\" si vous disposez d'une adresse IP fixe).*\n",
        "\n",
        "![Configuration autorisation ports entrants pour ssh](img/EMR_config_ssh_01.png)\n",
        "\n",
        "<u>Une fois cette étape réalisée vous devriez avoir une configuration semblable à la mienne</u> :\n",
        "\n",
        "![Configuration ssh terminée](img/EMR_config_ssh_02.png)\n",
        "\n",
        "### 4.8.2 Création du tunnel ssh vers le Driver\n",
        "\n",
        "On peut maintenant établir le **tunnel SSH** vers le **Driver**. <br />\n",
        "Pour cela on récupère les informations de connexion fournis par Amazon <br />\n",
        "depuis la page du service EMR / Cluster / onglet Récapitulatif en <br />\n",
        "cliquant sur \"**Activer la connexion Web**\"\n",
        "\n",
        "![Activer la connexion Web](img/EMR_tunnel_ssh_01.png)\n",
        "\n",
        "<u>On récupère ensuite la commande fournis par Amazon pour **établir le tunnel SSH**</u> :\n",
        "\n",
        "![Récupérer la commande pour établir le tunnel ssh](img/EMR_tunnel_ssh_02.png)\n",
        "\n",
        "<u>Dans mon cas, la commande ne fonctionne pas tel</u> quel et j'ai du **l'adapter à ma configuration**. <br />\n",
        "La **clé ssh** se situe dans un dossier \"**.ssh**\" elle-même située dans <br />\n",
        "mon **répertoire personnel** dont le symbole est, sous Linux, identifié par un tilde \"**~**\".\n",
        "\n",
        "Ayant suivi le cours [Réalisez des calculs distribués sur des données massives / Lancement d'une application à partir du driver](https://openclassrooms.com/fr/courses/4297166-realisez-des-calculs-distribues-sur-des-donnees-massives) <br />\n",
        "j'ai choisi d'utiliser le port **5555** au lieu du **8157**, même si le choix n'est pas très important.<br />\n",
        "    j'ai également rencontré un <u>problème de compatibilité</u> avec <br />\n",
        "l'argument \"**-N**\" (liste des arguments et leur significations <br />\n",
        "disponibles [ici](https://explainshell.com/explain?cmd=ssh+-L+-N+-f+-l+-D)) j'ai décidé de simplement le supprimer.\n",
        "\n",
        "<u>Finalement, j'utilise la commande suivante dans un terminal pour établir <br />\n",
        "    mon tunnel ssh (seul l'URL change d'une instance à une autre)</u> : <br />\n",
        "\"**ssh -i ~/.ssh/p8-ec2.pem -D 5555 hadoop@ec2-35-180-91-39.eu-west-3.compute.amazonaws.com**\"\n",
        "\n",
        "<u>On inscrit \"**yes**\" pour valider la connexion et si <br />\n",
        "    la connexion est établit on obtient le résultat suivant</u> :\n",
        "\n",
        "![Création du tunnel SSH](img/EMR_connexion_ssh_01.png)\n",
        "\n",
        "Nous avons **correctement établi le tunnel ssh avec le driver** sur le port \"5555\".\n",
        "\n",
        "### 4.8.3 Configuration de FoxyProxy\n",
        "\n",
        "Une dernière étape est nécessaire pour accéder à nos applications, <br />\n",
        "en demandant à notre navigateur d'emprunter le tunnel ssh.<br />\n",
        "J'utilise pour cela **FoxyProxy**.\n",
        "[Une fois encore, vous pouvez utiliser le cours pour le configurer](https://openclassrooms.com/fr/courses/4297166-realisez-des-calculs-distribues-sur-des-donnees-massives/4308701-realisez-la-maintenance-dun-cluster#/id/r-4356554).\n",
        "\n",
        "Sinon, ouvrez la configuration de **FoxyProxy** et <u>cliquez sur **Ajouter**</u> en haut à gauche <br />\n",
        "puis renseigner les éléments comme dans la capture ci-dessous :\n",
        "\n",
        "![Configuration FoxyProxy Etape 1](img/EMR_foxyproxy_config_01.png)\n",
        "\n",
        "<u>On obtient le résultat ci-dessous</u> :\n",
        "\n",
        "![Configuration FoxyProxy Etape 2](img/EMR_foxyproxy_config_02.png)\n",
        "\n",
        "\n",
        "### 4.8.4 Accès aux applications du serveur EMR via le tunnel ssh\n",
        "\n",
        "\n",
        "<u>Avant d'établir notre **tunnel ssh** nous avions ça</u> :\n",
        "\n",
        "![avant tunnel ssh](img/EMR_tunnel_ssh_avant.png)\n",
        "\n",
        "<u>On active le **tunnel ssh** comme vu précédemment puis on demande <br />\n",
        "à notre navigateur de l'utiliser avec **FoxyProxy**</u> :\n",
        "\n",
        "![FoxyProxy activation](img/EMR_foxyproxy_activation.png)\n",
        "\n",
        "<u>On peut maintenant s'apercevoir que plusieurs applications nous sont accessibles</u> :\n",
        "\n",
        "![avant tunnel ssh](img/EMR_tunnel_ssh_apres.png)\n",
        "\n",
        "## 4.9 Connexion au notebook JupyterHub\n",
        "\n",
        "Pour se connecter à **JupyterHub** en vue d'exécuter notre **notebook**, <br />\n",
        "il faut commencer par <u>cliquer sur l'application **JupyterHub**</u> apparu <br />\n",
        "depuis que nous avons configuré le **tunnel ssh** et **foxyproxy** sur <br />\n",
        "notre navigateur (actualisez la page si ce n’est pas le cas).\n",
        "\n",
        "![Démarrage de JupyterHub](img/EMR_jupyterhub_connexion_01.png)\n",
        "\n",
        "On passe les éventuels avertissements de sécurité puis <br />\n",
        "nous arrivons sur une page de connexion.\n",
        "    \n",
        "<u>On se connecte avec les informations par défaut</u> :\n",
        " - <u>login</u>: **jovyan**\n",
        " - <u>password</u>: **jupyter**\n",
        " \n",
        "![Connexion à JupyterHub](img/EMR_jupyterhub_connexion_02.png)\n",
        "\n",
        "Nous arrivons ensuite dans un dossier vierge de notebook.<br />\n",
        "Il suffit d'en créer un en cliquant sur \"**New**\" en haut à droite.\n",
        "\n",
        "![Liste et création des notebook](img/EMR_jupyterhub_creer_notebooks.png)\n",
        "\n",
        "Il est également possible d'en <u>uploader un directement dans notre **bucket S3**</u>.\n",
        "\n",
        "Grace à la <u>**persistance** paramétrée à l'instanciation du cluster <br />\n",
        "nous sommes actuellement dans l'arborescence de notre **bucket S3**</u>\n",
        "\n",
        "![Notebook stockés sur S3](img/EMR_jupyterhub_S3.png)\n",
        "\n",
        "Je décide d'**importer un notebook déjà rédigé en local directement <br />\n",
        "sur S3** et je l'ouvre depuis **l'interface JupyterHub**.\n",
        "\n",
        "## 4.10 Exécution du code\n",
        "\n",
        "Je décide d'exécuter cette partie du code depuis **JupyterHub hébergé sur notre cluster EMR**.<br />\n",
        "Pour ne pas alourdir inutilement les explications du **notebook**, je ne réexpliquerai pas les étapes communes <br />\n",
        "que nous avons déjà vues dans la première partie où l'on a exécuté le code localement sur notre machine virtuelle Ubuntu.\n",
        "\n",
        "<u>Avant de commencer</u>, il faut s'assurer d'utiliser le **kernel pyspark**.\n",
        "\n",
        "**En utilisant ce kernel, une session spark est créé à l'exécution de la première cellule**. <br />\n",
        "Il n'est donc **plus nécessaire d'exécuter le code \"spark = (SparkSession ...\"** comme lors <br />\n",
        "de l'exécution de notre notebook en local sur notre VM Ubuntu."
      ]
    },
    {
      "metadata": {
        "id": "4e759c1e"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.10.1 Démarrage de la session Spark"
      ]
    },
    {
      "metadata": {
        "colab": {
          "referenced_widgets": [
            ""
          ]
        },
        "id": "e5f0fbe1",
        "outputId": "cc838294-1257-4d72-8adb-162085a69b4e",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "# L'exécution de cette cellule démarre l'application Spark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Starting Spark application\n",
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>0</td><td>application_1683515387863_0001</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-4-143.eu-west-3.compute.internal:20888/proxy/application_1683515387863_0001/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-8-222.eu-west-3.compute.internal:8042/node/containerlogs/container_1683515387863_0001_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "SparkSession available as 'spark'.\n",
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "id": "3aba202f"
      },
      "cell_type": "markdown",
      "source": [
        "<u>Affichage des informations sur la session en cours et liens vers Spark UI</u> :"
      ]
    },
    {
      "metadata": {
        "id": "fb788991",
        "outputId": "fdac2f1d-fd5c-4a9b-e14e-9c6d8947f88c",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "%%info"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Current session configs: <tt>{'driverMemory': '1000M', 'executorCores': 2, 'proxyUser': 'jovyan', 'kind': 'pyspark'}</tt><br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>0</td><td>application_1683515387863_0001</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-4-143.eu-west-3.compute.internal:20888/proxy/application_1683515387863_0001/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-8-222.eu-west-3.compute.internal:8042/node/containerlogs/container_1683515387863_0001_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "id": "27ac9832"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.10.2 Installation des packages\n",
        "\n",
        "Les packages nécessaires ont été installé via l'étape de **bootstrap** à l'instanciation du serveur.\n",
        "\n",
        "### 4.10.3 Import des librairies"
      ]
    },
    {
      "metadata": {
        "colab": {
          "referenced_widgets": [
            ""
          ]
        },
        "id": "ad562eab",
        "outputId": "b2e0eaac-a13b-4c92-a053-62b0e4c3a2dd",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from PIL import Image\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras import Model\n",
        "from pyspark.sql.functions import col, pandas_udf, PandasUDFType, element_at, split\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler, PCA\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "id": "83663cbd"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.10.4 Définition des PATH pour charger les images et enregistrer les résultats\n",
        "\n",
        "Nous accédons directement à nos **données sur S3** comme si elles étaient **stockées localement**."
      ]
    },
    {
      "metadata": {
        "colab": {
          "referenced_widgets": [
            ""
          ]
        },
        "id": "46be859d",
        "outputId": "3ffc80fe-e628-40ea-854e-06cebfcb5a75",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "PATH = 's3://yass-p8-data'\n",
        "PATH_Data = PATH+'/Test'\n",
        "PATH_Result = PATH+'/Results'\n",
        "print('PATH:        '+\\\n",
        "      PATH+'\\nPATH_Data:   '+\\\n",
        "      PATH_Data+'\\nPATH_Result: '+PATH_Result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "PATH:        s3://yass-p8-data\nPATH_Data:   s3://yass-p8-data/Test\nPATH_Result: s3://yass-p8-data/Results",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cf883c20"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.10.5 Traitement des données"
      ]
    },
    {
      "metadata": {
        "id": "2ffe93f5"
      },
      "cell_type": "markdown",
      "source": [
        "#### 4.10.5.1 Chargement des données"
      ]
    },
    {
      "metadata": {
        "colab": {
          "referenced_widgets": [
            ""
          ]
        },
        "id": "7e4b319a",
        "outputId": "5a256601-d4bc-4802-e118-f3f36bae54d2",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "images = spark.read.format(\"binaryFile\") \\\n",
        "  .option(\"pathGlobFilter\", \"*.jpg\") \\\n",
        "  .option(\"recursiveFileLookup\", \"true\") \\\n",
        "  .load(PATH_Data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "colab": {
          "referenced_widgets": [
            ""
          ]
        },
        "id": "16bfeb4d",
        "outputId": "3c2ca103-25e7-4091-b1fa-380ba0704f6e",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "images.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "+--------------------+-------------------+------+--------------------+\n|                path|   modificationTime|length|             content|\n+--------------------+-------------------+------+--------------------+\n|s3://yass-p8-data...|2023-04-26 16:30:23|125135|[FF D8 FF E0 00 1...|\n|s3://yass-p8-data...|2023-04-26 16:30:23|124785|[FF D8 FF E0 00 1...|\n|s3://yass-p8-data...|2023-04-26 16:30:23|123514|[FF D8 FF E0 00 1...|\n|s3://yass-p8-data...|2023-04-26 16:30:23|122958|[FF D8 FF E0 00 1...|\n|s3://yass-p8-data...|2023-04-26 16:30:23|122807|[FF D8 FF E0 00 1...|\n+--------------------+-------------------+------+--------------------+\nonly showing top 5 rows",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8b32ac34"
      },
      "cell_type": "markdown",
      "source": [
        "<u>Je ne conserve que le **path** de l'image et j'ajoute <br />\n",
        "    une colonne contenant les **labels** de chaque image</u> :"
      ]
    },
    {
      "metadata": {
        "colab": {
          "referenced_widgets": [
            ""
          ]
        },
        "id": "a52ab808",
        "outputId": "03149032-68b4-476b-9127-248afc5356e8",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "images = images.withColumn('label', element_at(split(images['path'], '/'),-2))\n",
        "print(images.printSchema())\n",
        "print(images.select('path','label').show(5,False))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "root\n |-- path: string (nullable = true)\n |-- modificationTime: timestamp (nullable = true)\n |-- length: long (nullable = true)\n |-- content: binary (nullable = true)\n |-- label: string (nullable = true)\n\nNone\n+---------------------------------------------+-----------+\n|path                                         |label      |\n+---------------------------------------------+-----------+\n|s3://yass-p8-data/Test/apple_hit_1/r0_115.jpg|apple_hit_1|\n|s3://yass-p8-data/Test/apple_hit_1/r0_119.jpg|apple_hit_1|\n|s3://yass-p8-data/Test/apple_hit_1/r0_107.jpg|apple_hit_1|\n|s3://yass-p8-data/Test/apple_hit_1/r0_143.jpg|apple_hit_1|\n|s3://yass-p8-data/Test/apple_hit_1/r0_111.jpg|apple_hit_1|\n+---------------------------------------------+-----------+\nonly showing top 5 rows\n\nNone",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8f15b199"
      },
      "cell_type": "markdown",
      "source": [
        "#### 4.10.5.2 Préparation du modèle"
      ]
    },
    {
      "metadata": {
        "colab": {
          "referenced_widgets": [
            ""
          ]
        },
        "id": "ec7c7165",
        "outputId": "2adadb0d-599a-4371-f3da-bea11a180217",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "model = MobileNetV2(weights='imagenet',\n",
        "                    include_top=True,\n",
        "                    input_shape=(224, 224, 3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n\r    8192/14536120 [..............................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r11755520/14536120 [=======================>......] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r14536120/14536120 [==============================] - 0s 0us/step",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab": {
          "referenced_widgets": [
            ""
          ]
        },
        "id": "1b9bc650",
        "outputId": "7996a048-907c-473a-be69-92e547b037c7",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "new_model = Model(inputs=model.input,\n",
        "                  outputs=model.layers[-2].output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "colab": {
          "referenced_widgets": [
            ""
          ]
        },
        "id": "a0d497f2",
        "outputId": "a81c63bd-d231-4753-c793-a7c65ba434bb",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "brodcast_weights = sc.broadcast(new_model.get_weights())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "colab": {
          "referenced_widgets": [
            ""
          ]
        },
        "id": "1bc0bf14",
        "outputId": "e927eec0-be14-4d07-feae-3c637391b69e",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n                                )]                                                                \n                                                                                                  \n Conv1 (Conv2D)                 (None, 112, 112, 32  864         ['input_1[0][0]']                \n                                )                                                                 \n                                                                                                  \n bn_Conv1 (BatchNormalization)  (None, 112, 112, 32  128         ['Conv1[0][0]']                  \n                                )                                                                 \n                                                                                                  \n Conv1_relu (ReLU)              (None, 112, 112, 32  0           ['bn_Conv1[0][0]']               \n                                )                                                                 \n                                                                                                  \n expanded_conv_depthwise (Depth  (None, 112, 112, 32  288        ['Conv1_relu[0][0]']             \n wiseConv2D)                    )                                                                 \n                                                                                                  \n expanded_conv_depthwise_BN (Ba  (None, 112, 112, 32  128        ['expanded_conv_depthwise[0][0]']\n tchNormalization)              )                                                                 \n                                                                                                  \n expanded_conv_depthwise_relu (  (None, 112, 112, 32  0          ['expanded_conv_depthwise_BN[0][0\n ReLU)                          )                                ]']                              \n                                                                                                  \n expanded_conv_project (Conv2D)  (None, 112, 112, 16  512        ['expanded_conv_depthwise_relu[0]\n                                )                                [0]']                            \n                                                                                                  \n expanded_conv_project_BN (Batc  (None, 112, 112, 16  64         ['expanded_conv_project[0][0]']  \n hNormalization)                )                                                                 \n                                                                                                  \n block_1_expand (Conv2D)        (None, 112, 112, 96  1536        ['expanded_conv_project_BN[0][0]'\n                                )                                ]                                \n                                                                                                  \n block_1_expand_BN (BatchNormal  (None, 112, 112, 96  384        ['block_1_expand[0][0]']         \n ization)                       )                                                                 \n                                                                                                  \n block_1_expand_relu (ReLU)     (None, 112, 112, 96  0           ['block_1_expand_BN[0][0]']      \n                                )                                                                 \n                                                                                                  \n block_1_pad (ZeroPadding2D)    (None, 113, 113, 96  0           ['block_1_expand_relu[0][0]']    \n                                )                                                                 \n                                                                                                  \n block_1_depthwise (DepthwiseCo  (None, 56, 56, 96)  864         ['block_1_pad[0][0]']            \n nv2D)                                                                                            \n                                                                                                  \n block_1_depthwise_BN (BatchNor  (None, 56, 56, 96)  384         ['block_1_depthwise[0][0]']      \n malization)                                                                                      \n                                                                                                  \n block_1_depthwise_relu (ReLU)  (None, 56, 56, 96)   0           ['block_1_depthwise_BN[0][0]']   \n                                                                                                  \n block_1_project (Conv2D)       (None, 56, 56, 24)   2304        ['block_1_depthwise_relu[0][0]'] \n                                                                                                  \n block_1_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_1_project[0][0]']        \n lization)                                                                                        \n                                                                                                  \n block_2_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_1_project_BN[0][0]']     \n                                                                                                  \n block_2_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_2_expand[0][0]']         \n ization)                                                                                         \n                                                                                                  \n block_2_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_2_expand_BN[0][0]']      \n                                                                                                  \n block_2_depthwise (DepthwiseCo  (None, 56, 56, 144)  1296       ['block_2_expand_relu[0][0]']    \n nv2D)                                                                                            \n                                                                                                  \n block_2_depthwise_BN (BatchNor  (None, 56, 56, 144)  576        ['block_2_depthwise[0][0]']      \n malization)                                                                                      \n                                                                                                  \n block_2_depthwise_relu (ReLU)  (None, 56, 56, 144)  0           ['block_2_depthwise_BN[0][0]']   \n                                                                                                  \n block_2_project (Conv2D)       (None, 56, 56, 24)   3456        ['block_2_depthwise_relu[0][0]'] \n                                                                                                  \n block_2_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_2_project[0][0]']        \n lization)                                                                                        \n                                                                                                  \n block_2_add (Add)              (None, 56, 56, 24)   0           ['block_1_project_BN[0][0]',     \n                                                                  'block_2_project_BN[0][0]']     \n                                                                                                  \n block_3_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_2_add[0][0]']            \n                                                                                                  \n block_3_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_3_expand[0][0]']         \n ization)                                                                                         \n                                                                                                  \n block_3_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_3_expand_BN[0][0]']      \n                                                                                                  \n block_3_pad (ZeroPadding2D)    (None, 57, 57, 144)  0           ['block_3_expand_relu[0][0]']    \n                                                                                                  \n block_3_depthwise (DepthwiseCo  (None, 28, 28, 144)  1296       ['block_3_pad[0][0]']            \n nv2D)                                                                                            \n                                                                                                  \n block_3_depthwise_BN (BatchNor  (None, 28, 28, 144)  576        ['block_3_depthwise[0][0]']      \n malization)                                                                                      \n                                                                                                  \n block_3_depthwise_relu (ReLU)  (None, 28, 28, 144)  0           ['block_3_depthwise_BN[0][0]']   \n                                                                                                  \n block_3_project (Conv2D)       (None, 28, 28, 32)   4608        ['block_3_depthwise_relu[0][0]'] \n                                                                                                  \n block_3_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_3_project[0][0]']        \n lization)                                                                                        \n                                                                                                  \n block_4_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_3_project_BN[0][0]']     \n                                                                                                  \n block_4_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_4_expand[0][0]']         \n ization)                                                                                         \n                                                                                                  \n block_4_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_4_expand_BN[0][0]']      \n                                                                                                  \n block_4_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_4_expand_relu[0][0]']    \n nv2D)                                                                                            \n                                                                                                  \n block_4_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_4_depthwise[0][0]']      \n malization)                                                                                      \n                                                                                                  \n block_4_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_4_depthwise_BN[0][0]']   \n                                                                                                  \n block_4_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_4_depthwise_relu[0][0]'] \n                                                                                                  \n block_4_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_4_project[0][0]']        \n lization)                                                                                        \n                                                                                                  \n block_4_add (Add)              (None, 28, 28, 32)   0           ['block_3_project_BN[0][0]',     \n                                                                  'block_4_project_BN[0][0]']     \n                                                                                                  \n block_5_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_4_add[0][0]']            \n                                                                                                  \n block_5_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_5_expand[0][0]']         \n ization)                                                                                         \n                                                                                                  \n block_5_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_5_expand_BN[0][0]']      \n                                                                                                  \n block_5_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_5_expand_relu[0][0]']    \n nv2D)                                                                                            \n                                                                                                  \n block_5_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_5_depthwise[0][0]']      \n malization)                                                                                      \n                                                                                                  \n block_5_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_5_depthwise_BN[0][0]']   \n                                                                                                  \n block_5_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_5_depthwise_relu[0][0]'] \n                                                                                                  \n block_5_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_5_project[0][0]']        \n lization)                                                                                        \n                                                                                                  \n block_5_add (Add)              (None, 28, 28, 32)   0           ['block_4_add[0][0]',            \n                                                                  'block_5_project_BN[0][0]']     \n                                                                                                  \n block_6_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_5_add[0][0]']            \n                                                                                                  \n block_6_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_6_expand[0][0]']         \n ization)                                                                                         \n                                                                                                  \n block_6_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_6_expand_BN[0][0]']      \n                                                                                                  \n block_6_pad (ZeroPadding2D)    (None, 29, 29, 192)  0           ['block_6_expand_relu[0][0]']    \n                                                                                                  \n block_6_depthwise (DepthwiseCo  (None, 14, 14, 192)  1728       ['block_6_pad[0][0]']            \n nv2D)                                                                                            \n                                                                                                  \n block_6_depthwise_BN (BatchNor  (None, 14, 14, 192)  768        ['block_6_depthwise[0][0]']      \n malization)                                                                                      \n                                                                                                  \n block_6_depthwise_relu (ReLU)  (None, 14, 14, 192)  0           ['block_6_depthwise_BN[0][0]']   \n                                                                                                  \n block_6_project (Conv2D)       (None, 14, 14, 64)   12288       ['block_6_depthwise_relu[0][0]'] \n                                                                                                  \n block_6_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_6_project[0][0]']        \n lization)                                                                                        \n                                                                                                  \n block_7_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_6_project_BN[0][0]']     \n                                                                                                  \n block_7_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_7_expand[0][0]']         \n ization)                                                                                         \n                                                                                                  \n block_7_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_7_expand_BN[0][0]']      \n                                                                                                  \n block_7_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_7_expand_relu[0][0]']    \n nv2D)                                                                                            \n                                                                                                  \n block_7_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_7_depthwise[0][0]']      \n malization)                                                                                      \n                                                                                                  \n block_7_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_7_depthwise_BN[0][0]']   \n                                                                                                  \n block_7_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_7_depthwise_relu[0][0]'] \n                                                                                                  \n block_7_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_7_project[0][0]']        \n lization)                                                                                        \n                                                                                                  \n block_7_add (Add)              (None, 14, 14, 64)   0           ['block_6_project_BN[0][0]',     \n                                                                  'block_7_project_BN[0][0]']     \n                                                                                                  \n block_8_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_7_add[0][0]']            \n                                                                                                  \n block_8_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_8_expand[0][0]']         \n ization)                                                                                         \n                                                                                                  \n block_8_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_8_expand_BN[0][0]']      \n                                                                                                  \n block_8_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_8_expand_relu[0][0]']    \n nv2D)                                                                                            \n                                                                                                  \n block_8_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_8_depthwise[0][0]']      \n malization)                                                                                      \n                                                                                                  \n block_8_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_8_depthwise_BN[0][0]']   \n                                                                                                  \n block_8_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_8_depthwise_relu[0][0]'] \n                                                                                                  \n block_8_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_8_project[0][0]']        \n lization)                                                                                        \n                                                                                                  \n block_8_add (Add)              (None, 14, 14, 64)   0           ['block_7_add[0][0]',            \n                                                                  'block_8_project_BN[0][0]']     \n                                                                                                  \n block_9_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_8_add[0][0]']            \n                                                                                                  \n block_9_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_9_expand[0][0]']         \n ization)                                                                                         \n                                                                                                  \n block_9_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_9_expand_BN[0][0]']      \n                                                                                                  \n block_9_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_9_expand_relu[0][0]']    \n nv2D)                                                                                            \n                                                                                                  \n block_9_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_9_depthwise[0][0]']      \n malization)                                                                                      \n                                                                                                  \n block_9_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_9_depthwise_BN[0][0]']   \n                                                                                                  \n block_9_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_9_depthwise_relu[0][0]'] \n                                                                                                  \n block_9_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_9_project[0][0]']        \n lization)                                                                                        \n                                                                                                  \n block_9_add (Add)              (None, 14, 14, 64)   0           ['block_8_add[0][0]',            \n                                                                  'block_9_project_BN[0][0]']     \n                                                                                                  \n block_10_expand (Conv2D)       (None, 14, 14, 384)  24576       ['block_9_add[0][0]']            \n                                                                                                  \n block_10_expand_BN (BatchNorma  (None, 14, 14, 384)  1536       ['block_10_expand[0][0]']        \n lization)                                                                                        \n                                                                                                  \n block_10_expand_relu (ReLU)    (None, 14, 14, 384)  0           ['block_10_expand_BN[0][0]']     \n                                                                                                  \n block_10_depthwise (DepthwiseC  (None, 14, 14, 384)  3456       ['block_10_expand_relu[0][0]']   \n onv2D)                                                                                           \n                                                                                                  \n block_10_depthwise_BN (BatchNo  (None, 14, 14, 384)  1536       ['block_10_depthwise[0][0]']     \n rmalization)                                                                                     \n                                                                                                  \n block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0          ['block_10_depthwise_BN[0][0]']  \n                                                                                                  \n block_10_project (Conv2D)      (None, 14, 14, 96)   36864       ['block_10_depthwise_relu[0][0]']\n                                                                                                  \n block_10_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_10_project[0][0]']       \n alization)                                                                                       \n                                                                                                  \n block_11_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_10_project_BN[0][0]']    \n                                                                                                  \n block_11_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_11_expand[0][0]']        \n lization)                                                                                        \n                                                                                                  \n block_11_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_11_expand_BN[0][0]']     \n                                                                                                  \n block_11_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_11_expand_relu[0][0]']   \n onv2D)                                                                                           \n                                                                                                  \n block_11_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_11_depthwise[0][0]']     \n rmalization)                                                                                     \n                                                                                                  \n block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_11_depthwise_BN[0][0]']  \n                                                                                                  \n block_11_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_11_depthwise_relu[0][0]']\n                                                                                                  \n block_11_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_11_project[0][0]']       \n alization)                                                                                       \n                                                                                                  \n block_11_add (Add)             (None, 14, 14, 96)   0           ['block_10_project_BN[0][0]',    \n                                                                  'block_11_project_BN[0][0]']    \n                                                                                                  \n block_12_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_11_add[0][0]']           \n                                                                                                  \n block_12_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_12_expand[0][0]']        \n lization)                                                                                        \n                                                                                                  \n block_12_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_12_expand_BN[0][0]']     \n                                                                                                  \n block_12_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_12_expand_relu[0][0]']   \n onv2D)                                                                                           \n                                                                                                  \n block_12_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_12_depthwise[0][0]']     \n rmalization)                                                                                     \n                                                                                                  \n block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_12_depthwise_BN[0][0]']  \n                                                                                                  \n block_12_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_12_depthwise_relu[0][0]']\n                                                                                                  \n block_12_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_12_project[0][0]']       \n alization)                                                                                       \n                                                                                                  \n block_12_add (Add)             (None, 14, 14, 96)   0           ['block_11_add[0][0]',           \n                                                                  'block_12_project_BN[0][0]']    \n                                                                                                  \n block_13_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_12_add[0][0]']           \n                                                                                                  \n block_13_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_13_expand[0][0]']        \n lization)                                                                                        \n                                                                                                  \n block_13_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_13_expand_BN[0][0]']     \n                                                                                                  \n block_13_pad (ZeroPadding2D)   (None, 15, 15, 576)  0           ['block_13_expand_relu[0][0]']   \n                                                                                                  \n block_13_depthwise (DepthwiseC  (None, 7, 7, 576)   5184        ['block_13_pad[0][0]']           \n onv2D)                                                                                           \n                                                                                                  \n block_13_depthwise_BN (BatchNo  (None, 7, 7, 576)   2304        ['block_13_depthwise[0][0]']     \n rmalization)                                                                                     \n                                                                                                  \n block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)   0           ['block_13_depthwise_BN[0][0]']  \n                                                                                                  \n block_13_project (Conv2D)      (None, 7, 7, 160)    92160       ['block_13_depthwise_relu[0][0]']\n                                                                                                  \n block_13_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_13_project[0][0]']       \n alization)                                                                                       \n                                                                                                  \n block_14_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_13_project_BN[0][0]']    \n                                                                                                  \n block_14_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_14_expand[0][0]']        \n lization)                                                                                        \n                                                                                                  \n block_14_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_14_expand_BN[0][0]']     \n                                                                                                  \n block_14_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_14_expand_relu[0][0]']   \n onv2D)                                                                                           \n                                                                                                  \n block_14_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_14_depthwise[0][0]']     \n rmalization)                                                                                     \n                                                                                                  \n block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_14_depthwise_BN[0][0]']  \n                                                                                                  \n block_14_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_14_depthwise_relu[0][0]']\n                                                                                                  \n block_14_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_14_project[0][0]']       \n alization)                                                                                       \n                                                                                                  \n block_14_add (Add)             (None, 7, 7, 160)    0           ['block_13_project_BN[0][0]',    \n                                                                  'block_14_project_BN[0][0]']    \n                                                                                                  \n block_15_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_14_add[0][0]']           \n                                                                                                  \n block_15_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_15_expand[0][0]']        \n lization)                                                                                        \n                                                                                                  \n block_15_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_15_expand_BN[0][0]']     \n                                                                                                  \n block_15_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_15_expand_relu[0][0]']   \n onv2D)                                                                                           \n                                                                                                  \n block_15_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_15_depthwise[0][0]']     \n rmalization)                                                                                     \n                                                                                                  \n block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_15_depthwise_BN[0][0]']  \n                                                                                                  \n block_15_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_15_depthwise_relu[0][0]']\n                                                                                                  \n block_15_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_15_project[0][0]']       \n alization)                                                                                       \n                                                                                                  \n block_15_add (Add)             (None, 7, 7, 160)    0           ['block_14_add[0][0]',           \n                                                                  'block_15_project_BN[0][0]']    \n                                                                                                  \n block_16_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_15_add[0][0]']           \n                                                                                                  \n block_16_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_16_expand[0][0]']        \n lization)                                                                                        \n                                                                                                  \n block_16_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_16_expand_BN[0][0]']     \n                                                                                                  \n block_16_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_16_expand_relu[0][0]']   \n onv2D)                                                                                           \n                                                                                                  \n block_16_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_16_depthwise[0][0]']     \n rmalization)                                                                                     \n                                                                                                  \n block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_16_depthwise_BN[0][0]']  \n                                                                                                  \n block_16_project (Conv2D)      (None, 7, 7, 320)    307200      ['block_16_depthwise_relu[0][0]']\n                                                                                                  \n block_16_project_BN (BatchNorm  (None, 7, 7, 320)   1280        ['block_16_project[0][0]']       \n alization)                                                                                       \n                                                                                                  \n Conv_1 (Conv2D)                (None, 7, 7, 1280)   409600      ['block_16_project_BN[0][0]']    \n                                                                                                  \n Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)  5120        ['Conv_1[0][0]']                 \n                                                                                                  \n out_relu (ReLU)                (None, 7, 7, 1280)   0           ['Conv_1_bn[0][0]']              \n                                                                                                  \n global_average_pooling2d (Glob  (None, 1280)        0           ['out_relu[0][0]']               \n alAveragePooling2D)                                                                              \n                                                                                                  \n==================================================================================================\nTotal params: 2,257,984\nTrainable params: 2,223,872\nNon-trainable params: 34,112\n__________________________________________________________________________________________________",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab": {
          "referenced_widgets": [
            ""
          ]
        },
        "id": "be8fe2b9",
        "outputId": "0b09a155-fabc-490d-efb1-ed2ff7207984",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "def model_fn():\n",
        "    \"\"\"\n",
        "    Returns a MobileNetV2 model with top layer removed \n",
        "    and broadcasted pretrained weights.\n",
        "    \"\"\"\n",
        "    model = MobileNetV2(weights='imagenet',\n",
        "                        include_top=True,\n",
        "                        input_shape=(224, 224, 3))\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False\n",
        "    new_model = Model(inputs=model.input,\n",
        "                  outputs=model.layers[-2].output)\n",
        "    new_model.set_weights(brodcast_weights.value)\n",
        "    return new_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "id": "c032f135"
      },
      "cell_type": "markdown",
      "source": [
        "#### 4.10.5.3 Définition du processus de chargement des images <br/> et application de leur featurisation à travers l'utilisation de pandas UDF"
      ]
    },
    {
      "metadata": {
        "id": "77oyP0QoORbM",
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            ""
          ]
        },
        "outputId": "d8300fb5-a551-4d3a-d474-6a5958c4ba11"
      },
      "cell_type": "code",
      "source": [
        "def preprocess(content):\n",
        "    \"\"\"\n",
        "    Preprocesses raw image bytes for prediction.\n",
        "    \"\"\"\n",
        "    img = Image.open(io.BytesIO(content)).resize([224, 224]) #Open image from binary objects content and resize it\n",
        "    arr = img_to_array(img) # Convert img to to array\n",
        "    return preprocess_input(arr) #Reshape to (224,224,3)\n",
        "\n",
        "def featurize_series(model, content_series):\n",
        "    \"\"\"\n",
        "    Featurize a pd.Series of raw images using the input model.\n",
        "    :return: a pd.Series of image features\n",
        "    \"\"\"\n",
        "    input = np.stack(content_series.map(preprocess))\n",
        "    preds = model.predict(input)\n",
        "    # For some layers, output features will be multi-dimensional tensors.\n",
        "    # We flatten the feature tensors to vectors for easier storage in Spark DataFrames.\n",
        "    output = [p.flatten() for p in preds]\n",
        "    return pd.Series(output)\n",
        "\n",
        "@pandas_udf('array<float>', PandasUDFType.SCALAR_ITER)\n",
        "def featurize_udf(content_series_iter):\n",
        "    '''\n",
        "    This method is a Scalar Iterator pandas UDF wrapping our featurization function.\n",
        "    The decorator specifies that this returns a Spark DataFrame column of type ArrayType(FloatType).\n",
        "\n",
        "    :param content_series_iter: This argument is an iterator over batches of data, where each batch\n",
        "                              is a pandas Series of image data.\n",
        "    '''\n",
        "    # With Scalar Iterator pandas UDFs, we can load the model once and then re-use it\n",
        "    # for multiple data batches.  This amortizes the overhead of loading big models.\n",
        "    model = model_fn() \n",
        "    #Weights broadcasting\n",
        "    model.set_weights(brodcast_weights.value)\n",
        "    for content_series in content_series_iter:\n",
        "        yield featurize_series(model, content_series)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "/mnt1/yarn/usercache/livy/appcache/application_1683515387863_0001/container_1683515387863_0001_01_000001/pyspark.zip/pyspark/sql/pandas/functions.py:398: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "f23206e8"
      },
      "cell_type": "markdown",
      "source": [
        "#### 4.10.5.4 Exécutions des actions d'extractions de features"
      ]
    },
    {
      "metadata": {
        "colab": {
          "referenced_widgets": [
            ""
          ]
        },
        "id": "22d760c2",
        "outputId": "726980e7-363d-4467-cbde-0642dae1a413",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "# spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "colab": {
          "referenced_widgets": [
            ""
          ]
        },
        "id": "5e07fd68",
        "outputId": "da9ca07b-345b-4d91-dcbd-43a5d82aaf6d",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "features_df = images.repartition(24).select(col(\"path\"),\n",
        "                                            col(\"label\"),\n",
        "                                            featurize_udf(\"content\").alias(\"features\")\n",
        "                                           )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "colab": {
          "referenced_widgets": [
            ""
          ]
        },
        "id": "06a930b3",
        "outputId": "1dd6b923-2e8b-4de1-ea33-fa3371b1729b",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "print(PATH_Result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "s3://yass-p8-data/Results",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab": {
          "referenced_widgets": [
            ""
          ]
        },
        "id": "7c53ddd5",
        "outputId": "cb0de832-84a4-48c9-bc32-bdf9d940e8af",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "features_df.write.mode(\"overwrite\").parquet(PATH_Result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "id": "1fe01b72"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.10.6 Chargement des données enregistrées et validation du résultat"
      ]
    },
    {
      "metadata": {
        "colab": {
          "referenced_widgets": [
            ""
          ]
        },
        "id": "db18a784",
        "outputId": "5e5c2b02-946f-4e88-a416-6f8c43a8fdb3",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_parquet(PATH_Result, engine='pyarrow')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "colab": {
          "referenced_widgets": [
            ""
          ]
        },
        "id": "d750d2a8",
        "outputId": "e0829b27-5e66-471b-cb78-b35ece1b3fec",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "                                            path  ...                                           features\n0  s3://yass-p8-data/Test/apple_hit_1/r1_299.jpg  ...  [0.88818276, 0.9766362, 1.6814375, 0.0, 0.7473...\n1  s3://yass-p8-data/Test/apple_hit_1/r0_167.jpg  ...  [0.23584183, 0.13031594, 1.4356456, 0.0, 0.357...\n2   s3://yass-p8-data/Test/apple_hit_1/r1_43.jpg  ...  [0.008909265, 0.20073241, 2.0521822, 0.0, 0.17...\n3  s3://yass-p8-data/Test/apple_hit_1/r2_203.jpg  ...  [0.07983717, 0.30655688, 0.12255844, 0.0, 0.51...\n4   s3://yass-p8-data/Test/apple_hit_1/r1_63.jpg  ...  [0.16827433, 0.17030035, 0.27944311, 0.0, 0.48...\n\n[5 rows x 3 columns]",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab": {
          "referenced_widgets": [
            ""
          ]
        },
        "id": "b29205ff",
        "outputId": "6ddf9063-e3d8-4f92-826a-6a8915bd538b",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df.loc[0,'features'].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "(1280,)",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab": {
          "referenced_widgets": [
            ""
          ]
        },
        "id": "4fba6455",
        "outputId": "5a06d1bd-f114-48dd-c5b9-f14caff4986d",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "(3110, 3)",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            ""
          ]
        },
        "id": "yiadV-d9IZKv",
        "outputId": "f42e6ded-377f-4529-fbbb-6b0fea1fa1c2"
      },
      "cell_type": "code",
      "source": [
        "df1 = spark.read.parquet(PATH_Result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "id": "ib2MgA1JPOSL",
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            ""
          ]
        },
        "outputId": "fcdfefd7-cb83-4540-9d82-d3d9ff66d661"
      },
      "cell_type": "code",
      "source": [
        "df1.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "root\n |-- path: string (nullable = true)\n |-- label: string (nullable = true)\n |-- features: array (nullable = true)\n |    |-- element: float (containsNull = true)",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0oA1Ta7vhu6R"
      },
      "cell_type": "markdown",
      "source": [
        "## 4.11.6 Standard scalering image features"
      ]
    },
    {
      "metadata": {
        "id": "6lyAv4zq2Xjk",
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            ""
          ]
        },
        "outputId": "71712a10-b31f-49df-9246-c618b94e3c6c"
      },
      "cell_type": "code",
      "source": [
        "from pyspark.ml.linalg import VectorUDT, Vectors\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import ArrayType, DoubleType\n",
        "\n",
        "# define a UDF for converting numpy arrays to PySpark VectorUDT objects\n",
        "numpy_to_vector = udf(lambda a: Vectors.dense(a), returnType=VectorUDT())\n",
        "\n",
        "# apply the UDF to the 'features' column to create a new column of VectorUDT objects\n",
        "df1 = df1.withColumn('features_vector', numpy_to_vector(df1['features']))\n",
        "df1 = df1.withColumn('label_red', element_at(split(df1['label'], '_'),1))\n",
        "# drop the original 'features' column\n",
        "#df = df.drop('features')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            ""
          ]
        },
        "id": "ThLtKwUo8Ini",
        "outputId": "7b6d5aa6-3cc7-4b5b-a4a3-1f30240029d9",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df1.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "+--------------------+---------------+--------------------+--------------------+---------+\n|                path|          label|            features|     features_vector|label_red|\n+--------------------+---------------+--------------------+--------------------+---------+\n|s3://yass-p8-data...|    apple_hit_1|[0.3821219, 0.231...|[0.38212189078330...|    apple|\n|s3://yass-p8-data...|    apple_hit_1|[0.7551134, 1.278...|[0.75511342287063...|    apple|\n|s3://yass-p8-data...|    apple_hit_1|[0.77546775, 1.28...|[0.77546775341033...|    apple|\n|s3://yass-p8-data...|    apple_hit_1|[0.3894314, 0.012...|[0.38943138718605...|    apple|\n|s3://yass-p8-data...|    apple_hit_1|[0.0, 0.2023897, ...|[0.0,0.2023897022...|    apple|\n|s3://yass-p8-data...|    apple_hit_1|[0.60624766, 0.01...|[0.60624766349792...|    apple|\n|s3://yass-p8-data...|cabbage_white_1|[0.0, 0.5918547, ...|[0.0,0.5918546915...|  cabbage|\n|s3://yass-p8-data...|    apple_hit_1|[0.5113373, 0.581...|[0.51133728027343...|    apple|\n|s3://yass-p8-data...|    apple_hit_1|[0.9525132, 0.098...|[0.95251321792602...|    apple|\n|s3://yass-p8-data...|    apple_hit_1|[0.016577166, 0.4...|[0.01657716557383...|    apple|\n|s3://yass-p8-data...|    apple_hit_1|[0.17664088, 0.68...|[0.17664088308811...|    apple|\n|s3://yass-p8-data...|cabbage_white_1|[0.0, 0.37229428,...|[0.0,0.3722942769...|  cabbage|\n|s3://yass-p8-data...|    apple_hit_1|[0.49003655, 0.45...|[0.49003654718399...|    apple|\n|s3://yass-p8-data...|         pear_3|[1.4399418, 0.130...|[1.43994176387786...|     pear|\n|s3://yass-p8-data...|         pear_3|[0.36725032, 0.69...|[0.36725032329559...|     pear|\n|s3://yass-p8-data...|         pear_3|[0.33878618, 0.08...|[0.33878618478775...|     pear|\n|s3://yass-p8-data...|         pear_3|[0.60025746, 0.26...|[0.60025745630264...|     pear|\n|s3://yass-p8-data...|     cucumber_3|[0.9012141, 0.102...|[0.90121412277221...| cucumber|\n|s3://yass-p8-data...|    apple_red_3|[0.2401914, 0.148...|[0.24019140005111...|    apple|\n|s3://yass-p8-data...|     cucumber_3|[1.1408557, 0.485...|[1.14085566997528...| cucumber|\n+--------------------+---------------+--------------------+--------------------+---------+\nonly showing top 20 rows",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            ""
          ]
        },
        "id": "7zYqiS7Yh-3m",
        "outputId": "a7e2e6e5-9639-4c39-e0c0-5087f8501fd9",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler(\n",
        "    inputCol = 'features_vector', \n",
        "    outputCol = 'scaledFeatures',\n",
        "    withMean = True,\n",
        "    withStd = True\n",
        ").fit(df1)\n",
        "\n",
        "# when we transform the dataframe, the old\n",
        "# feature will still remain in it\n",
        "df_scaled = scaler.transform(df1)\n",
        "df_scaled.show(6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "+--------------------+-----------+--------------------+--------------------+---------+--------------------+\n|                path|      label|            features|     features_vector|label_red|      scaledFeatures|\n+--------------------+-----------+--------------------+--------------------+---------+--------------------+\n|s3://yass-p8-data...|apple_hit_1|[0.3821219, 0.231...|[0.38212189078330...|    apple|[0.04212617474026...|\n|s3://yass-p8-data...|apple_hit_1|[0.7551134, 1.278...|[0.75511342287063...|    apple|[0.91827456645018...|\n|s3://yass-p8-data...|apple_hit_1|[0.77546775, 1.28...|[0.77546775341033...|    apple|[0.96608641318808...|\n|s3://yass-p8-data...|apple_hit_1|[0.3894314, 0.012...|[0.38943138718605...|    apple|[0.05929601096048...|\n|s3://yass-p8-data...|apple_hit_1|[0.0, 0.2023897, ...|[0.0,0.2023897022...|    apple|[-0.8554692161614...|\n|s3://yass-p8-data...|apple_hit_1|[0.60624766, 0.01...|[0.60624766349792...|    apple|[0.56859237681661...|\n+--------------------+-----------+--------------------+--------------------+---------+--------------------+\nonly showing top 6 rows",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            ""
          ]
        },
        "id": "gZYIsykV6g_a",
        "outputId": "d602ea45-b693-462b-f00a-99224d9e6426",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df_scaled.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "root\n |-- path: string (nullable = true)\n |-- label: string (nullable = true)\n |-- features: array (nullable = true)\n |    |-- element: float (containsNull = true)\n |-- features_vector: vector (nullable = true)\n |-- label_red: string (nullable = true)\n |-- scaledFeatures: vector (nullable = true)",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "f9fG7puLk_fJ"
      },
      "cell_type": "markdown",
      "source": [
        "## 3.10 Performing PCA"
      ]
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            ""
          ]
        },
        "id": "yA96VxQElGlQ",
        "outputId": "cc066d92-f63c-4144-aa66-fc59a09344df",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "n_components = 20\n",
        "pca = PCA(\n",
        "    k = n_components, \n",
        "    inputCol = 'scaledFeatures', \n",
        "    outputCol = 'pcaFeatures'\n",
        ").fit(df_scaled)\n",
        "print('Cumulative variance', pca.explainedVariance.toArray().sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "Cumulative variance 0.5376154532383266",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449,
          "referenced_widgets": [
            ""
          ]
        },
        "id": "3fLfP7yNmQtQ",
        "outputId": "8e04eef1-f3cd-43b8-bf7d-4d543ce64828",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "variances = pca.explainedVariance.toArray()\n",
        "# Compute the cumulative explained variance\n",
        "cumulative_variances = np.cumsum(variances)\n",
        "\n",
        "# Plot the explained variance ratios\n",
        "plt.bar(range(1, n_components + 1), variances, label='Individual explained variance')\n",
        "plt.plot(range(1, n_components + 1), cumulative_variances,'-s', label='Cumulative explained variance', color='red')\n",
        "plt.xlabel('Number of principal components')\n",
        "plt.ylabel('Explained variance ratio')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            ""
          ]
        },
        "id": "9-eCglmzmMXq",
        "outputId": "2ed3a98e-a22b-4367-c231-08ca1eef2ce1",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "n_components = 2\n",
        "Pca = PCA(\n",
        "    k = n_components, \n",
        "    inputCol = 'scaledFeatures', \n",
        "    outputCol = 'pcaFeatures'\n",
        ").fit(df_scaled)\n",
        "\n",
        "df_pca = Pca.transform(df_scaled)\n",
        "print('Explained Variance Ratio', Pca.explainedVariance.toArray())\n",
        "df_pca.show(6)\n",
        "X_pca = df_pca.rdd.map(lambda row: row.pcaFeatures).collect()\n",
        "X_pca = np.array(X_pca)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "Explained Variance Ratio [0.1133648  0.06571123]\n+--------------------+-----------+--------------------+--------------------+---------+--------------------+--------------------+\n|                path|      label|            features|     features_vector|label_red|      scaledFeatures|         pcaFeatures|\n+--------------------+-----------+--------------------+--------------------+---------+--------------------+--------------------+\n|s3://yass-p8-data...|apple_hit_1|[0.3821219, 0.231...|[0.38212189078330...|    apple|[0.04212617474026...|[1.56348457055567...|\n|s3://yass-p8-data...|apple_hit_1|[0.7551134, 1.278...|[0.75511342287063...|    apple|[0.91827456645018...|[12.0309400335016...|\n|s3://yass-p8-data...|apple_hit_1|[0.77546775, 1.28...|[0.77546775341033...|    apple|[0.96608641318808...|[7.84802238865728...|\n|s3://yass-p8-data...|apple_hit_1|[0.3894314, 0.012...|[0.38943138718605...|    apple|[0.05929601096048...|[-1.4119891840638...|\n|s3://yass-p8-data...|apple_hit_1|[0.0, 0.2023897, ...|[0.0,0.2023897022...|    apple|[-0.8554692161614...|[0.49386895954679...|\n|s3://yass-p8-data...|apple_hit_1|[0.60624766, 0.01...|[0.60624766349792...|    apple|[0.56859237681661...|[-3.2051583848850...|\n+--------------------+-----------+--------------------+--------------------+---------+--------------------+--------------------+\nonly showing top 6 rows",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e0BAe4bV-djr",
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            ""
          ]
        },
        "outputId": "baeade93-cd71-43c9-d1d2-21772a4f9d49"
      },
      "cell_type": "code",
      "source": [
        "# change default style figure and font size\n",
        "def plot_pca(X, y):\n",
        "    \"\"\"Plot of the 2-dimensional image features\"\"\"\n",
        "    labels = np.array(df_pca.select('label').rdd.flatMap(lambda x: x).collect())\n",
        "    u_labels = np.unique(labels)\n",
        "\n",
        "    for i in u_labels:\n",
        "        plt.scatter(X[labels == i , 0] , X[labels == i , 1] , label = f'{i}')\n",
        "    plt.title(f'PCA Scatter plot', fontsize=14 )\n",
        "    plt.legend(loc='upper right')# bbox_to_anchor=(0.5, -0.2), ncol=len(u_labels)) #,\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569,
          "referenced_widgets": [
            ""
          ]
        },
        "id": "sMoFTtrF_PeV",
        "outputId": "b7f7069a-5f7b-4822-d226-3005cd362005",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "plot_pca(X_pca, \"label_red\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "id": "2SD1mEXzvk7Y"
      },
      "cell_type": "markdown",
      "source": [
        "Save PCA dataframe"
      ]
    },
    {
      "metadata": {
        "id": "QbHC6suDvCoo",
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            ""
          ]
        },
        "outputId": "d9190b46-384a-4e95-f808-4c61496c5d1e"
      },
      "cell_type": "code",
      "source": [
        "PATH_pca = PATH+'/Results/PcaFeatures'\n",
        "df_pca.write.mode(\"overwrite\").parquet(PATH_pca)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "id": "efe5348d"
      },
      "cell_type": "markdown",
      "source": [
        "Nous venons de valider le processus sur un jeu de données allégé en local <br />\n",
        "où nous avons simulé un cluster de machines en répartissant la charge de travail <br />\n",
        "sur différents cœurs de processeur au sein d'une même machine.\n",
        "\n",
        "Nous allons maintenant généraliser le processus en déployant notre solution <br />\n",
        "sur un réel cluster de machines et nous travaillerons désormais sur la totalité <br />\n",
        "des 22819 images de notre dossier \"Test\"."
      ]
    },
    {
      "metadata": {
        "id": "72974aab"
      },
      "cell_type": "markdown",
      "source": [
        "<u>On peut également constater la présence des fichiers <br />\n",
        "    au format \"**parquet**\" sur le **serveur S3**</u> :\n",
        "\n",
        "![Affichage des résultats sur S3](img/S3_Results.png)\n",
        "\n",
        "## 4.11 Suivi de l'avancement des tâches avec le Serveur d'Historique Spark\n",
        "\n",
        "Il est possible de voir l'avancement des tâches en cours <br />\n",
        "avec le **serveur d'historique Spark**.\n",
        "\n",
        "![Accès au serveur d'historique spark](img/EMR_serveur_historique_spark_acces.png)\n",
        "\n",
        "**Il est également possible de revenir et d'étudier les tâches <br />\n",
        "qui ont été réalisé, afin de debugger, optimiser les futurs <br />\n",
        "tâches à réaliser.**\n",
        "\n",
        "<u>Lorsque la commande \"**features_df.write.mode(\"overwrite\").parquet(PATH_Result)**\" <br />\n",
        "était en cours, nous pouvions observer son état d'avancement</u> :\n",
        "\n",
        "![Progression execution script](img/EMR_jupyterhub_avancement.png)\n",
        "\n",
        "<u>Le **serveur d'historique Spark** nous permet une vision beaucoup plus précise <br />\n",
        "de l'exécution des différentes tâche sur les différentes machines du cluster</u> :\n",
        "\n",
        "![Suivi des tâches spark](img/EMR_SHSpark_01.png)\n",
        "\n",
        "On peut également constater que notre cluster de calcul a mis <br />\n",
        "un tout petit peu **moins de 8 minutes** pour traiter les **22 688 images**.\n",
        "\n",
        "![Temps de traitement](img/EMR_SHSpark_02.png)\n"
      ]
    },
    {
      "metadata": {
        "id": "b22d65bf"
      },
      "cell_type": "markdown",
      "source": [
        "## 4.12 Résiliation de l'instance EMR\n",
        "\n",
        "Notre travail est maintenant terminé. <br />\n",
        "Le cluster de machines EMR est **facturé à la demande**, <br />\n",
        "et nous continuons d'être facturé même lorsque <br />\n",
        "les machines sont au repos.<br />\n",
        "Pour **optimiser la facturation**, il nous faut <br />\n",
        "maintenant **résilier le cluster**.\n",
        "\n",
        "<u>Je réalise cette commande depuis l'interface AWS</u> :\n",
        "\n",
        "1. Commencez par **désactiver le tunnel ssh dans FoxyProxy** pour éviter des problèmes de **timeout**.\n",
        "![Désactivation de FoxyProxy](img/EMR_foxyproxy_desactivation.png)\n",
        "2. Cliquez sur \"**Résilier**\"\n",
        "![Cliquez sur Résilier](img/EMR_resiliation_01.png)\n",
        "3. Confirmez la résiliation\n",
        "![Confirmez la résiliation](img/EMR_resiliation_02.png)\n",
        "4. La résiliation prend environ **1 minute**\n",
        "![Résiliation en cours](img/EMR_resiliation_03.png)\n",
        "5. La résiliation est effectuée\n",
        "![Résiliation terminée](img/EMR_resiliation_04.png)\n",
        "\n",
        "## 4.13 Cloner le serveur EMR (si besoin)\n",
        "\n",
        "Si nous devons de nouveau exécuter notre notebook dans les mêmes conditions, <br />\n",
        "il nous suffit de **cloner notre cluster** et ainsi en obtenir une copie fonctionnelle <br />\n",
        "sous 15/20 minutes, le temps de son instanciation.\n",
        "\n",
        "<u>Pour cela deux solutions</u> :\n",
        "1. <u>Depuis l'interface AWS</u> :\n",
        " 1. Cliquez sur \"**Cloner**\"\n",
        "   ![Cloner un cluster](img/EMR_cloner_01.png)\n",
        " 2. Dans notre cas nous ne souhaitons pas inclure d'étapes\n",
        "   ![Ne pas inclure d'étapes](img/EMR_cloner_02.png)\n",
        " 3. La configuration du cluster est recréée à l’identique. <br />\n",
        "    On peut revenir sur les différentes étapes si on souhaite apporter des modifications<br />\n",
        "    Quand tout est prêt, cliquez sur \"**Créer un cluster**\"\n",
        "  ![Vérification/Modification/Créer un cluster](img/EMR_cloner_03.png)\n",
        "2. <u>En ligne de commande</u> (avec AWS CLI d'installé et de configuré et en s'assurant <br />\n",
        "   de s'attribuer les droits nécessaires sur le compte AMI utilisé)\n",
        " 1. Cliquez sur \"**Exporter AWS CLI**\"\n",
        " ![Exporter AWS CLI](img/EMR_cloner_cli_01.png)\n",
        " 2. Copier/Coller la commande **depuis un terminal**\n",
        " ![Copier Coller Commande](img/EMR_cloner_cli_02.png)\n",
        "\n",
        "## 4.14 Arborescence du serveur S3 à la fin du projet\n",
        "\n",
        "<u>Pour information, voici **l'arborescence complète de mon bucket S3 p8-data** à la fin du projet</u> : <br />\n",
        "*Par soucis de lisibilité, je ne liste pas les 131 sous dossiers du répertoire \"Test\"*\n",
        "\n",
        "1. Results/_SUCCESS\n",
        "1. Results/part-00000-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
        "1. Results/part-00001-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
        "1. Results/part-00002-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
        "1. Results/part-00003-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
        "1. Results/part-00004-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
        "1. Results/part-00005-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
        "1. Results/part-00006-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
        "1. Results/part-00007-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
        "1. Results/part-00008-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
        "1. Results/part-00009-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
        "1. Results/part-00010-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
        "1. Results/part-00011-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
        "1. Results/part-00012-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
        "1. Results/part-00013-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
        "1. Results/part-00014-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
        "1. Results/part-00015-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
        "1. Results/part-00016-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
        "1. Results/part-00017-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
        "1. Results/part-00018-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
        "1. Results/part-00019-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
        "1. Results/part-00020-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
        "1. Results/part-00021-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
        "1. Results/part-00022-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
        "1. Results/part-00023-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
        "1. Test/\n",
        "1. bootstrap-emr.sh\n",
        "1. jupyter-s3-conf.json\n",
        "1. jupyter/jovyan/.s3keep\n",
        "1. jupyter/jovyan/P8_01_Notebook.ipynb\n",
        "1. jupyter/jovyan/_metadata\n",
        "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/\n",
        "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/file-perm.sqlite\n",
        "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/nbconvert/\n",
        "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/nbconvert/templates/\n",
        "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/nbconvert/templates/html/\n",
        "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/nbconvert/templates/latex/\n",
        "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/nbsignatures.db\n",
        "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/notebook_secret\n",
        "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.ipynb_checkpoints/\n",
        "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.ipynb_checkpoints/Untitled-checkpoint.ipynb\n",
        "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.ipynb_checkpoints/Untitled1-checkpoint.ipynb\n",
        "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.ipynb_checkpoints/test3-checkpoint.ipynb\n",
        "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/Untitled.ipynb\n",
        "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/Untitled1.ipynb\n",
        "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/test3.ipynb"
      ]
    },
    {
      "metadata": {
        "id": "4eba46f9"
      },
      "cell_type": "markdown",
      "source": [
        "# 5. Conclusion\n",
        "\n",
        "Nous avons réalisé ce projet **en deux temps** en tenant <br />\n",
        "compte des contraintes qui nous ont été imposées.\n",
        "\n",
        "Nous avons **dans un premier temps développé notre solution en local** <br />\n",
        "sur une machine virtuelle dans un environnement Linux Ubuntu.\n",
        "\n",
        "La <u>première phase</u> a consisté à **installer l'environnement de travail Spark**. <br />\n",
        "**Spark** a un paramètre qui nous permet de travaillé en local et nous permet <br />\n",
        "ainsi de **simuler du calcul partagé** en considérant <br />\n",
        "**chaque cœur d'un processeur comme un worker indépendant**.<br />\n",
        "Nous avons travaillé sur un plus **petit jeu de donnée**, l'idée était <br />\n",
        "simplement de **valider le bon fonctionnement de la solution**.\n",
        "\n",
        "Nous avons fait le choix de réaliser du **transfert learning** <br />\n",
        "à partir du model **MobileNetV2**.<br />\n",
        "Ce modèle a été retenu pour sa **légèreté** et sa **rapidité d'exécution** <br />\n",
        "ainsi que pour la **faible dimension de son vecteur en sortie**.\n",
        "\n",
        "Les résultats ont été enregistrés sur disque en plusieurs <br />\n",
        "partitions au format \"**parquet**\".\n",
        "\n",
        "<u>**La solution a parfaitement fonctionné en mode local**</u>.\n",
        "\n",
        "La <u>deuxième phase</u> a consisté à créer un **réel cluster de calculs**. <br />\n",
        "L'objectif était de pouvoir **anticiper une future augmentation de la charge de travail**.\n",
        "\n",
        "Le meilleur choix retenu a été l'utilisation du prestataire de services **Amazon Web Services** <br />\n",
        "qui nous permet de **louer à la demande de la puissance de calculs**, <br />\n",
        "pour un **coût tout à fait acceptable**.<br />\n",
        "Ce service se nomme **EC2** et se classe parmi les offres **Infrastructure As A Service** (IAAS).\n",
        "\n",
        "Nous sommes allez plus loin en utilisant un service de plus <br />\n",
        "haut niveau (**Plateforme As A Service** PAAS)<br />\n",
        "en utilisant le service **EMR** qui nous permet d'un seul coup <br />\n",
        "d'**instancier plusieurs serveur (un cluster)** sur lesquels <br />\n",
        "nous avons pu demander l'installation et la configuration de plusieurs<br />\n",
        "programmes et librairies nécessaires à notre projet comme **Spark**, <br />\n",
        "**Hadoop**, **JupyterHub** ainsi que la librairie **TensorFlow**.\n",
        "\n",
        "En plus d'être plus **rapide et efficace à mettre en place**, nous avons <br />\n",
        "la **certitude du bon fonctionnement de la solution**, celle-ci ayant été <br />\n",
        "préalablement validé par les ingénieurs d'Amazon.\n",
        "\n",
        "Nous avons également pu installer, sans difficulté, **les packages <br />\n",
        "nécessaires sur l'ensembles des machines du cluster**.\n",
        "\n",
        "Enfin, avec très peu de modification, et plus simplement encore, <br />\n",
        "nous avons pu **exécuter notre notebook comme nous l'avions fait localement**.<br />\n",
        "Nous avons cette fois-ci exécuté le traitement sur **l'ensemble des images de notre dossier \"Test\"**.\n",
        "\n",
        "Nous avons opté pour le service **Amazon S3** pour **stocker les données de notre projet**. <br />\n",
        "S3 offre, pour un faible coût, toutes les conditions dont nous avons besoin pour stocker <br />\n",
        "et exploiter de manière efficace nos données.<br />\n",
        "L'espace alloué est potentiellement **illimité**, mais les coûts seront fonction de l'espace utilisé.\n",
        "\n",
        "Il nous sera **facile de faire face à une monté de la charge de travail** en **redimensionnant** <br />\n",
        "simplement notre cluster de machines (horizontalement et/ou verticalement au besoin), <br />\n",
        "les coûts augmenteront en conséquence mais resteront nettement inférieurs aux coûts engendrés <br />\n",
        "par l'achat de matériels ou par la location de serveurs dédiés."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "pysparkkernel",
      "display_name": "PySpark",
      "language": "python"
    },
    "language_info": {
      "name": "pyspark",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "pygments_lexer": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}